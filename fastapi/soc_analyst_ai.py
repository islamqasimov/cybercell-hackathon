from typing import Dict, List, Optional
from datetime import datetime
import json
from jinja2 import Template

class SOCAnalystAI:
    """
    SOC Analyst AI: Generates human-readable security incident reports
    Combines template-based approach with pattern recognition
    """
    
    def __init__(self):
        self.report_template = Template("""
# Security Incident Report

**Alert ID**: {{ alert_id }}
**Generated**: {{ timestamp }}
**Severity**: {{ severity | upper }}
**Risk Score**: {{ risk_score }}/10

## Summary
{{ summary }}

## What Happened
{{ what_happened }}

## Evidence
{% for evidence_item in evidence %}
- **{{ evidence_item.key }}**: {{ evidence_item.value }}
{% endfor %}

## Attack Indicators
{% for indicator in indicators %}
- {{ indicator }}
{% endfor %}

## Affected Assets
- **Host**: {{ host }}
- **IP Address**: {{ ip_address }}
- **Service**: {{ service }}
{% if vulnerabilities %}
- **Known Vulnerabilities**: {{ vulnerabilities | length }} found
{% endif %}

## Immediate Actions Required
{% for action in immediate_actions %}
{{ loop.index }}. {{ action }}
{% endfor %}

## Recommended Next Steps
{% for step in next_steps %}
{{ loop.index }}. {{ step }}
{% endfor %}

## Confidence & Rationale
**Confidence Level**: {{ confidence }}%

{{ rationale }}

---
*Report generated by SOC Analyst AI*
""")
    
    def analyze_alert(
        self,
        alert_data: Dict,
        anomaly_data: Optional[Dict] = None,
        vuln_data: Optional[Dict] = None,
        logs: Optional[List[str]] = None
    ) -> Dict:
        """
        Generate comprehensive incident report
        
        Args:
            alert_data: Wazuh alert information
            anomaly_data: Anomaly detection results
            vuln_data: Nessus vulnerability data
            logs: Sample log lines for evidence
            
        Returns:
            Structured report dict
        """
        rule_id = alert_data.get('rule_id', '')
        rule_description = alert_data.get('rule_description', 'Unknown security event')
        host = alert_data.get('host', 'unknown')
        severity_level = alert_data.get('severity', 0)
        
        # Determine attack type and pattern
        attack_type = self._identify_attack_type(rule_id, rule_description, logs)
        
        # Calculate composite risk
        risk_score = self._calculate_risk_score(
            severity_level,
            anomaly_data,
            vuln_data
        )
        
        # Determine severity label
        if risk_score >= 7:
            severity = "critical"
        elif risk_score >= 5:
            severity = "high"
        elif risk_score >= 3:
            severity = "medium"
        else:
            severity = "low"
        
        # Build evidence list
        evidence = self._extract_evidence(alert_data, anomaly_data, vuln_data)
        
        # Generate indicators of compromise
        indicators = self._generate_indicators(alert_data, logs, attack_type)
        
        # Create summary
        summary = self._generate_summary(attack_type, host, rule_description)
        
        # What happened (detailed narrative)
        what_happened = self._generate_narrative(
            attack_type,
            host,
            alert_data,
            anomaly_data
        )
        
        # Generate immediate actions
        immediate_actions = self._generate_immediate_actions(
            attack_type,
            severity,
            alert_data
        )
        
        # Generate next steps
        next_steps = self._generate_next_steps(attack_type, vuln_data)
        
        # Generate rationale
        rationale = self._generate_rationale(
            attack_type,
            anomaly_data,
            vuln_data,
            severity_level
        )
        
        # Calculate confidence
        confidence = self._calculate_confidence(alert_data, anomaly_data)
        
        # Build report
        report = {
            'alert_id': alert_data.get('alert_id', 'N/A'),
            'timestamp': datetime.utcnow().isoformat(),
            'severity': severity,
            'risk_score': risk_score,
            'attack_type': attack_type,
            'summary': summary,
            'what_happened': what_happened,
            'evidence': evidence,
            'indicators': indicators,
            'host': host,
            'ip_address': alert_data.get('src_ip', 'N/A'),
            'service': alert_data.get('service', 'web'),
            'vulnerabilities': vuln_data.get('vulnerabilities', []) if vuln_data else [],
            'immediate_actions': immediate_actions,
            'next_steps': next_steps,
            'confidence': confidence,
            'rationale': rationale
        }
        
        return report
    
    def _identify_attack_type(self, rule_id: str, description: str, logs: Optional[List[str]]) -> str:
        """Identify attack type from rule and logs"""
        description_lower = description.lower()
        
        if 'sql' in description_lower or 'injection' in description_lower:
            return "SQL Injection"
        elif 'xss' in description_lower or 'script' in description_lower:
            return "Cross-Site Scripting (XSS)"
        elif 'brute' in description_lower or 'authentication failure' in description_lower:
            return "Brute Force Attack"
        elif 'scan' in description_lower or 'probe' in description_lower:
            return "Network Scanning"
        elif 'dos' in description_lower or 'flood' in description_lower:
            return "Denial of Service (DoS)"
        elif 'command' in description_lower or 'execution' in description_lower:
            return "Command Injection"
        elif 'file' in description_lower and 'traversal' in description_lower:
            return "Directory Traversal"
        else:
            return "Suspicious Activity"
    
    def _calculate_risk_score(
        self,
        severity: int,
        anomaly_data: Optional[Dict],
        vuln_data: Optional[Dict]
    ) -> float:
        """Calculate composite risk score (0-10)"""
        # Normalize Wazuh severity (0-15) to 0-10
        severity_score = min(severity / 1.5, 10)
        
        # Anomaly contribution
        anomaly_score = 0
        if anomaly_data and 'anomaly_score' in anomaly_data:
            anomaly_score = anomaly_data['anomaly_score'] * 10
        
        # Vulnerability contribution
        vuln_score = 0
        if vuln_data and 'max_cvss' in vuln_data:
            vuln_score = vuln_data['max_cvss']
        
        # Weighted composite
        risk = (0.35 * severity_score + 
                0.30 * anomaly_score + 
                0.25 * vuln_score + 
                0.10 * (5 if anomaly_score > 5 else 0))
        
        return round(min(risk, 10), 2)
    
    def _extract_evidence(
        self,
        alert_data: Dict,
        anomaly_data: Optional[Dict],
        vuln_data: Optional[Dict]
    ) -> List[Dict]:
        """Extract key evidence points"""
        evidence = [
            {'key': 'Rule ID', 'value': alert_data.get('rule_id', 'N/A')},
            {'key': 'Rule Description', 'value': alert_data.get('rule_description', 'N/A')},
            {'key': 'Wazuh Severity', 'value': f"{alert_data.get('severity', 0)}/15"},
        ]
        
        if alert_data.get('src_ip'):
            evidence.append({'key': 'Source IP', 'value': alert_data['src_ip']})
        
        if anomaly_data:
            evidence.append({
                'key': 'Anomaly Score',
                'value': f"{anomaly_data.get('anomaly_score', 0):.3f}"
            })
            if 'top_features' in anomaly_data:
                top_feature = list(anomaly_data['top_features'].keys())[0]
                evidence.append({
                    'key': 'Top Anomalous Feature',
                    'value': f"{top_feature} = {anomaly_data['top_features'][top_feature]}"
                })
        
        if vuln_data and 'vulnerabilities' in vuln_data:
            vulns = vuln_data['vulnerabilities']
            if vulns:
                evidence.append({
                    'key': 'Critical Vulnerabilities',
                    'value': f"{len([v for v in vulns if v.get('severity') == 'critical'])} found"
                })
        
        return evidence
    
    def _generate_indicators(
        self,
        alert_data: Dict,
        logs: Optional[List[str]],
        attack_type: str
    ) -> List[str]:
        """Generate indicators of compromise"""
        indicators = []
        
        if 'SQL' in attack_type:
            indicators.extend([
                "SQL syntax detected in HTTP parameters",
                "Multiple database error responses",
                "Unusual query patterns in application logs"
            ])
        elif 'Brute Force' in attack_type:
            indicators.extend([
                "High volume of authentication failures",
                "Sequential login attempts from single source",
                "Consistent timing between requests"
            ])
        elif 'XSS' in attack_type:
            indicators.extend([
                "JavaScript code in user input fields",
                "HTML/script tags in request parameters",
                "Attempts to bypass input validation"
            ])
        elif 'Scanning' in attack_type:
            indicators.extend([
                "Systematic enumeration of endpoints",
                "Requests to non-existent resources",
                "Known scanner user-agent strings"
            ])
        elif 'DoS' in attack_type:
            indicators.extend([
                "Abnormally high request rate",
                "Resource exhaustion patterns",
                "Connection flooding detected"
            ])
        
        # Add generic indicators
        if alert_data.get('src_ip'):
            indicators.append(f"Traffic from suspicious IP: {alert_data['src_ip']}")
        
        return indicators
    
    def _generate_summary(self, attack_type: str, host: str, description: str) -> str:
        """Generate one-line summary"""
        return f"{attack_type} detected against {host}. {description}"
    
    def _generate_narrative(
        self,
        attack_type: str,
        host: str,
        alert_data: Dict,
        anomaly_data: Optional[Dict]
    ) -> str:
        """Generate detailed narrative of what happened"""
        timestamp = alert_data.get('timestamp', datetime.utcnow())
        
        narrative = f"At {timestamp}, security monitoring systems detected {attack_type.lower()} "
        narrative += f"targeting {host}. "
        
        if anomaly_data and anomaly_data.get('anomaly_score', 0) > 0.5:
            narrative += "The activity showed significant deviation from normal behavioral patterns, "
            narrative += f"with an anomaly score of {anomaly_data['anomaly_score']:.2f}. "
        
        narrative += f"Wazuh rule {alert_data.get('rule_id', 'unknown')} was triggered, "
        narrative += f"indicating {alert_data.get('rule_description', 'suspicious activity').lower()}."
        
        return narrative
    
    def _generate_immediate_actions(
        self,
        attack_type: str,
        severity: str,
        alert_data: Dict
    ) -> List[str]:
        """Generate immediate action items"""
        actions = []
        
        if severity in ['critical', 'high']:
            if alert_data.get('src_ip'):
                actions.append(f"Block source IP {alert_data['src_ip']} at firewall")
            actions.append("Isolate affected host from network")
            actions.append("Capture memory dump and network traffic for forensics")
        
        actions.extend([
            "Review recent logs for additional indicators",
            "Verify if attack was successful or blocked",
            "Check for lateral movement or persistence mechanisms"
        ])
        
        if 'SQL' in attack_type:
            actions.append("Verify database integrity and check for data exfiltration")
        elif 'Brute Force' in attack_type:
            actions.append("Lock affected user accounts and force password resets")
        elif 'XSS' in attack_type:
            actions.append("Scan for stored XSS payloads in database")
        
        return actions
    
    def _generate_next_steps(self, attack_type: str, vuln_data: Optional[Dict]) -> List[str]:
        """Generate recommended next steps"""
        steps = [
            "Conduct full incident investigation and timeline analysis",
            "Update detection rules based on attack patterns observed",
            "Review and strengthen relevant security controls"
        ]
        
        if vuln_data and vuln_data.get('vulnerabilities'):
            steps.append("Prioritize patching identified vulnerabilities")
            steps.append("Implement virtual patching if immediate patching not possible")
        
        if 'SQL' in attack_type:
            steps.extend([
                "Implement parameterized queries throughout application",
                "Deploy Web Application Firewall (WAF) rules for SQLi"
            ])
        elif 'Brute Force' in attack_type:
            steps.extend([
                "Implement account lockout policies",
                "Deploy multi-factor authentication (MFA)",
                "Consider CAPTCHA for login forms"
            ])
        
        steps.append("Schedule security awareness training for development team")
        
        return steps
    
    def _generate_rationale(
        self,
        attack_type: str,
        anomaly_data: Optional[Dict],
        vuln_data: Optional[Dict],
        severity: int
    ) -> str:
        """Generate confidence rationale"""
        rationale = f"This incident was classified as {attack_type} based on "
        
        factors = []
        if severity >= 10:
            factors.append("high-severity Wazuh rule match")
        
        if anomaly_data and anomaly_data.get('anomaly_score', 0) > 0.7:
            factors.append("strong anomaly detection signal")
        
        if vuln_data and vuln_data.get('vulnerabilities'):
            factors.append("presence of exploitable vulnerabilities on target")
        
        factors.append("pattern matching against known attack signatures")
        
        rationale += ", ".join(factors) + ". "
        rationale += "The classification confidence is high due to correlation across multiple detection layers."
        
        return rationale
    
    def _calculate_confidence(self, alert_data: Dict, anomaly_data: Optional[Dict]) -> int:
        """Calculate confidence percentage"""
        confidence = 60  # Base confidence
        
        # Increase confidence based on factors
        if alert_data.get('severity', 0) >= 10:
            confidence += 15
        
        if anomaly_data:
            if anomaly_data.get('anomaly_score', 0) > 0.7:
                confidence += 15
            elif anomaly_data.get('anomaly_score', 0) > 0.5:
                confidence += 10
        
        if alert_data.get('src_ip'):
            confidence += 5
        
        if alert_data.get('rule_id'):
            confidence += 5
        
        return min(confidence, 99)  # Cap at 99%
    
    def generate_report_text(self, report_data: Dict) -> str:
        """Generate formatted text report from report data"""
        return self.report_template.render(**report_data)


# Example usage and testing
if __name__ == "__main__":
    soc_ai = SOCAnalystAI()
    
    # Example alert data
    sample_alert = {
        'alert_id': 'ALT-2024-001',
        'rule_id': '31103',
        'rule_description': 'SQL injection attempt detected',
        'host': 'juiceshop',
        'severity': 12,
        'src_ip': '10.0.0.100',
        'timestamp': datetime.utcnow(),
        'service': 'http'
    }
    
    sample_anomaly = {
        'anomaly_score': 0.85,
        'top_features': {
            'conn_count': 150,
            '5xx_count': 45,
            'unique_uris': 3
        }
    }
    
    sample_vulns = {
        'vulnerabilities': [
            {'cve': 'CVE-2023-1234', 'severity': 'critical', 'cvss': 9.8},
            {'cve': 'CVE-2023-5678', 'severity': 'high', 'cvss': 7.5}
        ],
        'max_cvss': 9.8
    }
    
    sample_logs = [
        "192.168.1.100 - - [18/Oct/2025:10:15:30] \"GET /api/products?id=1' OR '1'='1 HTTP/1.1\" 500",
        "192.168.1.100 - - [18/Oct/2025:10:15:31] \"GET /api/products?id=1 UNION SELECT * FROM users HTTP/1.1\" 500"
    ]
    
    # Generate report
    report = soc_ai.analyze_alert(
        sample_alert,
        sample_anomaly,
        sample_vulns,
        sample_logs
    )
    
    print("=== SOC ANALYST AI REPORT ===\n")
    print(json.dumps(report, indent=2, default=str))
    print("\n=== FORMATTED REPORT ===\n")
    print(soc_ai.generate_report_text(report))
